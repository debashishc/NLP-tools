{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(filepath):\n",
    "    \"\"\" Return sentences given a text file.\n",
    "    \"\"\"\n",
    "    with open(filepath, mode='r', encoding=\"ISO-8859-1\") as f:\n",
    "        data = f.read()\n",
    "    sentences = sent_tokenize(data)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labelled_text(text, novs, divs, label):\n",
    "    \"\"\" Create labelled text file with corresponding novelty and diversity values\n",
    "    \"\"\"\n",
    "    text_dict = dict()\n",
    "\n",
    "    for ix, t in enumerate(text):\n",
    "        text_dict[ix] = (t, novs[ix], divs[ix], label)\n",
    "        \n",
    "    return text_dict\n",
    "\n",
    "\n",
    "def write_to_csv(text_dict, filename):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # real labelled as 1, fake labelled as 0\n",
    "    fieldnames = [\"index\", \"text\", \"novelty\", \"diversity\", \"label\"]\n",
    "    with open(file=filename, mode='w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        data = [dict(zip(fieldnames, [k, values[0], values[1], values[2], values[3]]))\n",
    "                for k, values in text_dict.items()]\n",
    "        writer.writerows(data)\n",
    "\n",
    "# bad function name\n",
    "def create_labelled_dictionary(text, novelties, diversities, label):\n",
    "    \"\"\" Create labelled text file with no novelty or diversity values\n",
    "    \"\"\"\n",
    "    text_dict = dict()\n",
    "\n",
    "    for ix, t in enumerate(text):\n",
    "        text_dict[ix] = (t, novelties[ix], diversities[ix], label)\n",
    "\n",
    "    return text_dict\n",
    "\n",
    "\n",
    "def write_to_file(text_dict, filename):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # real labelled as 1, fake labelled as 0\n",
    "    fieldnames = [\"index\", \"text\", \"novelty\", \"diversity\", \"label\"]\n",
    "    with open(file=filename, mode='w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        data = [dict(zip(fieldnames, [k, values[0], values[1], values[2], values[3]]))\n",
    "                for k, values in text_dict.items()]\n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "def read_list(filename: str) -> list:\n",
    "    \"\"\" Read list from a text file containing\n",
    "    \"\"\"\n",
    "    with open(file=filename, mode='r', encoding=\"ISO-8859-1\") as f:\n",
    "        result_list = list()\n",
    "        data = f.read().split(',\\n')\n",
    "        for line in data[0:]:\n",
    "            result_list.extend(re.findall(\"\\d+\\.\\d+\", line))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10769 10769 10769\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = \"../data/emnlp_news.txt\"\n",
    "TEST_FILE = \"../data/test_emnlp.txt\"\n",
    "GENERATED_FILE = \"../data/generated_text3.txt\"\n",
    "\n",
    "# save these sentences and novelties to save computation time\n",
    "# corpus_sentences = get_sentences(DATA_FILE)  # 304222 sentences\n",
    "real_sentences = get_sentences(TEST_FILE) # 10785 sentences\n",
    "fake_sentences = get_sentences(GENERATED_FILE)  # 11055 sentences\n",
    "\n",
    "fake_diversities = read_list('jaccard_diversities_fake3.txt')\n",
    "fake_novelties = read_list('jaccard_novelties_fake3.txt')\n",
    "\n",
    "real_novelties = read_list('jaccard_novelties_real.txt')\n",
    "real_diversities = read_list('jaccard_diversities_real.txt')\n",
    "\n",
    "print(len(fake_sentences), len(fake_diversities), len(fake_novelties))\n",
    "print(len(real_sentences), len(real_diversities), len(real_novelties))\n",
    "\n",
    "real_text = get_sentences(DATA_FILE)\n",
    "fake_text = get_sentences(GENERATED_FILE)\n",
    "\n",
    "real_dict = create_labelled_dictionary(real_sentences, real_novelties, real_diversities, 1)\n",
    "write_to_file(real_dict, filename='labelled_real_metrics_jaccard.csv')\n",
    "\n",
    "# label fake text with 0\n",
    "fake_dict = create_labelled_dictionary(fake_sentences, fake_novelties, fake_diversities, 0)\n",
    "write_to_file(fake_dict, filename='labelled_fake_metrics_jaccard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
